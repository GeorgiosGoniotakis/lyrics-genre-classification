Title: Fully Connected - Words: 3000, Batch: 256, Epochs: 200, Outputs: 512

Results of Training Set

--------------------
Accuracy: 0.9786753484586428, F1 Score: 0.9779025509936111, Precision: 0.9781533788515182, Recall: 0.9776661528848923

              precision    recall  f1-score   support

           0       0.98      0.98      0.98     13170
           1       0.96      0.97      0.97      6048
           2       0.98      0.97      0.98      7020
           3       0.99      0.98      0.98     10425
           4       0.97      0.97      0.97      7642
           5       0.99      0.99      0.99     11777
           6       0.97      0.98      0.98     18547
           7       0.98      0.98      0.98     12692
           8       0.98      0.97      0.98     10969

   micro avg       0.98      0.98      0.98     98290
   macro avg       0.98      0.98      0.98     98290
weighted avg       0.98      0.98      0.98     98290
 samples avg       0.98      0.98      0.98     98290


[[12933     8    26     7    59     8    45    23    61]
 [   13  5872     7    21    35    13    53    26     8]
 [   24    11  6829    21    28     3    63     7    34]
 [   10    24    19 10246    13     7    81     8    17]
 [   30    50    12    13  7428     7    52    29    21]
 [   13    16     4     2     4 11638    24    47    29]
 [   43    55    32    53    47    18 18154   102    43]
 [   37    29     6     9    28    27   105 12437    14]
 [   89    21    17    18    30    39    88    10 10657]]

Results of Validation Set

--------------------
Accuracy: 0.3959344382382566, F1 Score: 0.36908961719255257, Precision: 0.3755813005203465, Recall: 0.36898472849402136

              precision    recall  f1-score   support

           0       0.51      0.58      0.54      4336
           1       0.39      0.28      0.33      1980
           2       0.22      0.14      0.17      2305
           3       0.27      0.24      0.26      3499
           4       0.42      0.37      0.39      2578
           5       0.51      0.57      0.54      3966
           6       0.35      0.42      0.38      6032
           7       0.50      0.53      0.51      4331
           8       0.22      0.18      0.20      3736

   micro avg       0.40      0.40      0.40     32763
   macro avg       0.38      0.37      0.37     32763
weighted avg       0.38      0.40      0.39     32763
 samples avg       0.40      0.40      0.40     32763


[[2507   34  186  189  203  126  525  158  408]
 [  72  561   58  193  193  196  297  282  128]
 [ 355   59  332  390  155  200  481   62  271]
 [ 280  146  282  846  153  316  916  131  429]
 [ 235  164   97  143  957  129  400  286  167]
 [ 139   89  111  253   88 2279  400  290  317]
 [ 480  147  238  543  218  355 2532  958  561]
 [ 146  117   24   94  173  424  930 2280  143]
 [ 734  113  195  455  146  468  839  108  678]]

Results of Test Set

--------------------
Accuracy: 0.39711268465388844, F1 Score: 0.3719302662569897, Precision: 0.3783152722146228, Recall: 0.3711650030325497

              precision    recall  f1-score   support

           0       0.52      0.56      0.54      4490
           1       0.40      0.30      0.34      1910
           2       0.24      0.16      0.19      2407
           3       0.25      0.23      0.24      3403
           4       0.41      0.37      0.39      2559
           5       0.52      0.59      0.55      3854
           6       0.35      0.42      0.39      6184
           7       0.50      0.53      0.51      4284
           8       0.22      0.19      0.20      3673

   micro avg       0.40      0.40      0.40     32764
   macro avg       0.38      0.37      0.37     32764
weighted avg       0.39      0.40      0.39     32764
 samples avg       0.40      0.40      0.40     32764


[[2496   42  220  218  159  144  578  185  448]
 [  65  573   59  210  190  156  289  235  133]
 [ 357   66  379  394  164  185  489   51  322]
 [ 277  157  274  784  170  277  890  138  436]
 [ 212  172  106  135  957  138  414  269  156]
 [ 128   92   93  202  100 2260  388  262  329]
 [ 453  150  219  623  245  333 2628 1015  518]
 [ 154  102   30  101  168  454  898 2251  126]
 [ 684   74  184  469  178  432  837  132  683]]

