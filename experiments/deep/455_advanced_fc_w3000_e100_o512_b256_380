Title: Fully Connected - Words: 3000, Batch: 256, Epochs: 100, Outputs: 512

Results of Training Set

--------------------
Accuracy: 0.9452131447756639, F1 Score: 0.943361049748023, Precision: 0.9463823338827244, Recall: 0.9407350169712413

              precision    recall  f1-score   support

           0       0.95      0.96      0.96     13170
           1       0.93      0.93      0.93      6048
           2       0.96      0.90      0.93      7020
           3       0.94      0.94      0.94     10425
           4       0.93      0.93      0.93      7642
           5       0.96      0.96      0.96     11777
           6       0.92      0.96      0.94     18547
           7       0.98      0.95      0.97     12692
           8       0.94      0.93      0.93     10969

   micro avg       0.95      0.95      0.95     98290
   macro avg       0.95      0.94      0.94     98290
weighted avg       0.95      0.95      0.95     98290
 samples avg       0.95      0.95      0.95     98290


[[12691    13    39    35    83    21   147    34   107]
 [   28  5646    16    55    65    44   114    31    49]
 [   89    29  6286   120    77    30   259    12   118]
 [   46    61    23  9788    45    54   302    16    90]
 [   83    96    34    41  7136    21   127    40    64]
 [   43    35    12    65    19 11347   122    50    84]
 [  113    93    64   166   115    62 17716   101   117]
 [   42    47     9    42    38    99   255 12112    48]
 [  178    47    43    88    60   107   251    12 10183]]

Results of Validation Set

--------------------
Accuracy: 0.4015200073253365, F1 Score: 0.3760235832076217, Precision: 0.3806005432607261, Recall: 0.37664533252874716

              precision    recall  f1-score   support

           0       0.52      0.57      0.54      4336
           1       0.37      0.31      0.34      1980
           2       0.24      0.14      0.18      2305
           3       0.28      0.26      0.27      3499
           4       0.41      0.39      0.40      2578
           5       0.52      0.59      0.55      3966
           6       0.35      0.42      0.38      6032
           7       0.52      0.52      0.52      4331
           8       0.21      0.18      0.19      3736

   micro avg       0.40      0.40      0.40     32763
   macro avg       0.38      0.38      0.38     32763
weighted avg       0.39      0.40      0.39     32763
 samples avg       0.40      0.40      0.40     32763


[[2485   51  166  206  217  115  487  163  446]
 [  67  611   53  198  183  194  277  251  146]
 [ 340   68  333  407  163  187  467   54  286]
 [ 282  164  243  920  174  298  901   83  434]
 [ 217  190   98  152 1016  127  365  256  157]
 [ 136  117   83  253   87 2321  403  255  311]
 [ 442  161  213  551  263  370 2544  918  570]
 [ 135  130   26   84  201  429  912 2265  149]
 [ 720  141  180  490  146  445  856   98  660]]

Results of Test Set

--------------------
Accuracy: 0.4012330606763521, F1 Score: 0.376337695479054, Precision: 0.38088676013302536, Recall: 0.37620372154038173

              precision    recall  f1-score   support

           0       0.53      0.56      0.54      4490
           1       0.37      0.32      0.34      1910
           2       0.24      0.15      0.19      2407
           3       0.26      0.25      0.26      3403
           4       0.40      0.39      0.40      2559
           5       0.52      0.58      0.55      3854
           6       0.36      0.44      0.39      6184
           7       0.52      0.51      0.51      4284
           8       0.22      0.19      0.21      3673

   micro avg       0.40      0.40      0.40     32764
   macro avg       0.38      0.38      0.38     32764
weighted avg       0.39      0.40      0.39     32764
 samples avg       0.40      0.40      0.40     32764


[[2499   54  208  225  174  142  590  158  440]
 [  73  607   44  190  212  147  285  207  145]
 [ 341   85  366  427  173  170  483   39  323]
 [ 249  170  264  840  165  266  918  108  423]
 [ 195  222  116  124 1003  131  354  255  159]
 [ 123  106   87  228  105 2242  378  227  358]
 [ 431  177  202  618  288  322 2697  937  512]
 [ 147  125   21  100  193  455  931 2179  133]
 [ 674   92  186  430  186  432  842  118  713]]

