Title: Fully Connected - Words: 3000, Batch: 256, Epochs: 200, Outputs: 512

Results of Training Set

--------------------
Accuracy: 0.9435751348051684, F1 Score: 0.9417413414584352, Precision: 0.9456064213593243, Recall: 0.9384568445205225

              precision    recall  f1-score   support

           0       0.95      0.97      0.96     13170
           1       0.93      0.93      0.93      6048
           2       0.97      0.89      0.93      7020
           3       0.94      0.93      0.94     10425
           4       0.93      0.94      0.93      7642
           5       0.96      0.96      0.96     11777
           6       0.91      0.96      0.93     18547
           7       0.98      0.95      0.96     12692
           8       0.94      0.92      0.93     10969

   micro avg       0.94      0.94      0.94     98290
   macro avg       0.95      0.94      0.94     98290
weighted avg       0.94      0.94      0.94     98290
 samples avg       0.94      0.94      0.94     98290


[[12724     9    35    30    90    12   145    28    97]
 [   29  5631    12    59    72    48   128    27    42]
 [  107    31  6247   130    83    38   258    10   116]
 [   61    71    34  9732    43    50   333    19    82]
 [   72    87    29    46  7146    32   139    30    61]
 [   40    33    21    72    20 11308   137    45   101]
 [  110    89    45   135   118    67 17803    89    91]
 [   55    42     7    40    43   104   295 12059    47]
 [  196    46    39    97    74    98   311    14 10094]]

Results of Validation Set

--------------------
Accuracy: 0.401550529560785, F1 Score: 0.37458135698128925, Precision: 0.3812153868525471, Recall: 0.37461619028466075

              precision    recall  f1-score   support

           0       0.51      0.58      0.54      4336
           1       0.37      0.29      0.33      1980
           2       0.25      0.15      0.18      2305
           3       0.28      0.26      0.27      3499
           4       0.41      0.39      0.40      2578
           5       0.52      0.58      0.55      3966
           6       0.35      0.44      0.39      6032
           7       0.52      0.50      0.51      4331
           8       0.22      0.18      0.19      3736

   micro avg       0.40      0.40      0.40     32763
   macro avg       0.38      0.37      0.37     32763
weighted avg       0.39      0.40      0.39     32763
 samples avg       0.40      0.40      0.40     32763


[[2529   37  164  201  204  112  524  153  412]
 [  71  582   51  203  213  190  280  247  143]
 [ 360   67  335  413  162  185  481   54  248]
 [ 285  165  247  907  166  269  950   90  420]
 [ 245  192   87  146 1005  126  361  261  155]
 [ 140  123   79  232   92 2291  466  216  327]
 [ 439  162  189  566  267  360 2663  864  522]
 [ 145  139   22   84  187  429  997 2187  141]
 [ 739  123  165  478  157  424  895   98  657]]

Results of Test Set

--------------------
Accuracy: 0.4032474667317788, F1 Score: 0.37799671818573866, Precision: 0.3840761378715187, Recall: 0.3773574501624528

              precision    recall  f1-score   support

           0       0.52      0.56      0.54      4490
           1       0.39      0.32      0.35      1910
           2       0.24      0.15      0.18      2407
           3       0.27      0.26      0.26      3403
           4       0.41      0.39      0.40      2559
           5       0.53      0.58      0.55      3854
           6       0.36      0.45      0.40      6184
           7       0.52      0.50      0.51      4284
           8       0.23      0.19      0.21      3673

   micro avg       0.40      0.40      0.40     32764
   macro avg       0.38      0.38      0.38     32764
weighted avg       0.39      0.40      0.40     32764
 samples avg       0.40      0.40      0.40     32764


[[2518   50  192  219  173  128  625  165  420]
 [  75  607   60  187  205  137  286  205  148]
 [ 360   81  354  424  183  167  499   35  304]
 [ 280  158  250  868  141  251  935  116  404]
 [ 203  193   97  136 1003  144  404  236  143]
 [ 130   99   86  254  106 2249  408  207  315]
 [ 444  169  219  592  288  315 2755  934  468]
 [ 168  110   34  108  190  446  963 2154  111]
 [ 685  101  172  456  187  414  850  104  704]]

