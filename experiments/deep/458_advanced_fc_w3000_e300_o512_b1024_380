Title: Fully Connected - Words: 3000, Batch: 1024, Epochs: 300, Outputs: 512

Results of Training Set

--------------------
Accuracy: 0.9836809441448774, F1 Score: 0.9831298036784276, Precision: 0.9829723464256498, Recall: 0.9833089231475609

              precision    recall  f1-score   support

           0       0.98      0.99      0.99     13170
           1       0.97      0.98      0.97      6048
           2       0.99      0.98      0.98      7020
           3       0.99      0.99      0.99     10425
           4       0.98      0.98      0.98      7642
           5       0.99      0.99      0.99     11777
           6       0.98      0.98      0.98     18547
           7       0.98      0.98      0.98     12692
           8       0.99      0.98      0.98     10969

   micro avg       0.98      0.98      0.98     98290
   macro avg       0.98      0.98      0.98     98290
weighted avg       0.98      0.98      0.98     98290
 samples avg       0.98      0.98      0.98     98290


[[13006    11    17     6    28     1    28    34    39]
 [    7  5932     4    13    26     4    33    21     8]
 [   13     7  6903    16    13     1    42     7    18]
 [    6    20    18 10296     8     1    59    14     3]
 [   32    56    11     5  7469     5    37    19     8]
 [   12    16     1     3     4 11672    15    33    21]
 [   39    60    33    34    35    10 18222    81    33]
 [   26    28     2     7    26    29   105 12463     6]
 [   79    15    18    14    23    22    60    15 10723]]

Results of Validation Set

--------------------
Accuracy: 0.39547660470652873, F1 Score: 0.3701873586886217, Precision: 0.37346776038662244, Recall: 0.3722460332245594

              precision    recall  f1-score   support

           0       0.49      0.60      0.54      4336
           1       0.37      0.30      0.33      1980
           2       0.23      0.18      0.20      2305
           3       0.28      0.25      0.26      3499
           4       0.43      0.35      0.39      2578
           5       0.50      0.58      0.53      3966
           6       0.35      0.38      0.36      6032
           7       0.50      0.55      0.52      4331
           8       0.22      0.17      0.19      3736

   micro avg       0.40      0.40      0.40     32763
   macro avg       0.37      0.37      0.37     32763
weighted avg       0.38      0.40      0.39     32763
 samples avg       0.40      0.40      0.40     32763


[[2600   45  190  199  158  131  429  190  394]
 [  74  587   74  193  172  200  255  290  135]
 [ 384   68  416  381  130  190  428   62  246]
 [ 328  152  321  877  139  330  808  120  424]
 [ 254  184  120  162  907  134  349  305  163]
 [ 171  116  120  256   93 2281  375  269  285]
 [ 546  177  304  567  224  378 2282 1021  533]
 [ 158  130   39   95  139  453  815 2370  132]
 [ 781  131  242  449  132  488  761  115  637]]

Results of Test Set

--------------------
Accuracy: 0.3986082285435234, F1 Score: 0.3723042315126273, Precision: 0.3743266715972935, Recall: 0.3741891971697691

              precision    recall  f1-score   support

           0       0.50      0.58      0.54      4490
           1       0.37      0.31      0.33      1910
           2       0.22      0.17      0.19      2407
           3       0.26      0.24      0.25      3403
           4       0.43      0.36      0.39      2559
           5       0.52      0.60      0.55      3854
           6       0.37      0.40      0.38      6184
           7       0.49      0.54      0.52      4284
           8       0.22      0.17      0.19      3673

   micro avg       0.40      0.40      0.40     32764
   macro avg       0.37      0.37      0.37     32764
weighted avg       0.39      0.40      0.39     32764
 samples avg       0.40      0.40      0.40     32764


[[2589   57  240  193  147  154  513  185  412]
 [  83  585   84  196  174  156  245  249  138]
 [ 402   77  416  417  149  182  431   50  283]
 [ 320  177  334  824  139  276  771  144  418]
 [ 227  198  147  149  917  133  369  281  138]
 [ 172  104  123  222   85 2295  302  256  295]
 [ 488  178  283  622  243  354 2473 1075  468]
 [ 184  123   31  110  147  436  786 2319  148]
 [ 717  101  270  452  150  437  777  127  642]]

