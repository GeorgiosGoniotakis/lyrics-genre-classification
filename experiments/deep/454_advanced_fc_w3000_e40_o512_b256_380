Title: Fully Connected - Words: 3000, Batch: 256, Epochs: 40, Outputs: 512

Results of Training Set

--------------------
Accuracy: 0.8038762844643402, F1 Score: 0.7965988028769985, Precision: 0.8085752295217902, Recall: 0.7877841216015761

              precision    recall  f1-score   support

           0       0.83      0.88      0.85     13170
           1       0.84      0.72      0.78      6048
           2       0.80      0.67      0.73      7020
           3       0.74      0.76      0.75     10425
           4       0.83      0.78      0.81      7642
           5       0.85      0.85      0.85     11777
           6       0.76      0.84      0.80     18547
           7       0.89      0.87      0.88     12692
           8       0.75      0.71      0.73     10969

   micro avg       0.80      0.80      0.80     98290
   macro avg       0.81      0.79      0.80     98290
weighted avg       0.81      0.80      0.80     98290
 samples avg       0.80      0.80      0.80     98290


[[11563    39   179   200   178    69   477   161   304]
 [   95  4381    90   323   167   202   399   217   174]
 [  345    81  4723   479   198   135   627    49   383]
 [  261   159   173  7944   124   232  1011    96   425]
 [  247   168   150   188  5989   121   419   143   217]
 [  168    94    88   276    80  9984   501   181   405]
 [  493   143   234   666   252   292 15574   368   525]
 [   92    65    29   134    70   376   648 11085   193]
 [  695   111   209   549   170   394   969   102  7770]]

Results of Validation Set

--------------------
Accuracy: 0.4054268534627476, F1 Score: 0.3803783622375224, Precision: 0.3878835950925539, Recall: 0.37809444048847995

              precision    recall  f1-score   support

           0       0.53      0.59      0.55      4336
           1       0.38      0.26      0.31      1980
           2       0.23      0.17      0.20      2305
           3       0.28      0.28      0.28      3499
           4       0.42      0.37      0.40      2578
           5       0.54      0.58      0.56      3966
           6       0.35      0.43      0.39      6032
           7       0.53      0.53      0.53      4331
           8       0.23      0.20      0.21      3736

   micro avg       0.41      0.41      0.41     32763
   macro avg       0.39      0.38      0.38     32763
weighted avg       0.40      0.41      0.40     32763
 samples avg       0.41      0.41      0.41     32763


[[2538   29  200  209  198  100  483  159  420]
 [  66  519   69  220  207  204  291  262  142]
 [ 342   58  395  432  139  169  444   47  279]
 [ 255  128  340  982  136  263  873   89  433]
 [ 234  161  134  182  966  120  380  245  156]
 [ 124  102  114  254   77 2302  407  235  351]
 [ 434  146  228  630  250  292 2570  916  566]
 [ 114  100   33   95  176  408  984 2278  143]
 [ 703  114  217  520  131  391  840   87  733]]

Results of Test Set

--------------------
Accuracy: 0.4072457575387621, F1 Score: 0.3828217007996146, Precision: 0.3909516878202474, Recall: 0.3797270997419261

              precision    recall  f1-score   support

           0       0.53      0.56      0.55      4490
           1       0.40      0.28      0.33      1910
           2       0.25      0.18      0.21      2407
           3       0.27      0.28      0.27      3403
           4       0.41      0.36      0.38      2559
           5       0.55      0.59      0.57      3854
           6       0.37      0.44      0.40      6184
           7       0.51      0.52      0.51      4284
           8       0.24      0.21      0.22      3673

   micro avg       0.41      0.41      0.41     32764
   macro avg       0.39      0.38      0.38     32764
weighted avg       0.40      0.41      0.40     32764
 samples avg       0.41      0.41      0.41     32764


[[2520   38  242  239  168  108  554  169  452]
 [  58  529   61  231  210  157  274  226  164]
 [ 325   74  433  490  153  148  442   36  306]
 [ 245  139  307  944  145  236  849  113  425]
 [ 197  168  119  166  931  122  412  283  161]
 [ 129   90  102  237   90 2268  370  222  346]
 [ 432  123  241  647  246  297 2719  982  497]
 [ 137   84   29  117  184  418  960 2226  129]
 [ 670   86  207  489  159  366  808  115  773]]

