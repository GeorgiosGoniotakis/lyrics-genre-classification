{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f89fb1a64f63d3cb1845778718e695d2e5e3c2f"
   },
   "source": [
    "# Music Genre Classification - Preprocessing (380K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "445677aec882614fdcf5e33c8c3bce80462a1122"
   },
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib/utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "0f031d4e082fa5e36862b1a8851ad739d231d0ae"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c51e71216669186f8fbab180cb0b07cb66ff505a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "ac9e04e2eaf81cc8fe0f88dc109c9cfc991cbe8b"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "255eacb1d2134623cf4b6bc7ecf91b5c42d6d19f"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "69bae3a9e1017d95eab6ebdd928522054ef2806d"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "47de3b76162ddc7a1785c4a925f208328c4e8915"
   },
   "outputs": [],
   "source": [
    "# Parameters and definitions\n",
    "RANDOM_SEED = 0\n",
    "VAL_SET_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "96e0dae0b6f3d3eb777e0fb4346da37ce9a4c959"
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbb4282c349d40ef1dd3e22eceaefb5028e44356"
   },
   "source": [
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "c73b0d56a143137e5cdb3e4f0f7901ffc0987fb4"
   },
   "outputs": [],
   "source": [
    "DATASET = \"../data/380000.csv\"\n",
    "OUT_DATASET = \"../data/380000_clean.csv\"\n",
    "FIGURES_DIR = \"../figures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f467191eecaaee9b4d99c6cd9e44329448c3da37"
   },
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d7670080c67178cbb698ce77a08ae11159a20198"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Loads the training and testing sets into the memory.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a385d0a5a872f85110d62202d6656e86d5c9344a"
   },
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "2b9e67b4a894ac2605c08e2aa084b38551256369"
   },
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ffb71680e2dbd385ad22d495952e26c35af9ae9"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "84cb6b345734df010b12b22896e262f8dc5fe6a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len. of data set: 362237\n"
     ]
    }
   ],
   "source": [
    "# Number of records\n",
    "prev_len = len(df)\n",
    "print(\"Len. of data set: {}\".format(prev_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanitize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len. of data set: 266556\n",
      "Number of elements removed: 95681\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with N/A values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Number of records after removal\n",
    "print(\"Len. of data set: {}\".format(len(df)))\n",
    "\n",
    "# Records removed\n",
    "print(\"Number of elements removed: {}\".format(prev_len - len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_s = df.copy()\n",
    "\n",
    "df_subset = preprocess_data(df_s.iloc[0][\"lyrics\"])\n",
    "\n",
    "# df_s = preprocess_data(df_s, col=\"lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh babi know im gonna cut right chase women made like think creat special purpos know what special feel babi let get lost dont need call work caus your boss real want show feel consid lucki that big deal well got key heart aint gonna need id rather open bodi show secret didnt know insid need lie big wide strong wont fit much tough talk like caus back got big ego huge ego love big ego much walk like caus back usual im humbl right dont choos leav could blue call arrog call confid decid find im work damn know im kill leg better yet thigh matter fact smile mayb eye boy site see kind someth like big wide strong wont fit much tough talk like caus back got big ego huge ego love big ego much walk like caus back walk like caus back talk like caus back back back walk like caus back big wide strong wont fit much tough talk like caus back got big ego huge ego huge ego love big ego much walk like caus back ego big must admit got everi reason feel like im bitch ego strong aint know dont need beat sing piano'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = preprocess_data(df_s.iloc[0:2], function_list=['lower','punct','custom'], col=\"lyrics\")\n",
    "\n",
    "df_test = preprocess_data(df_s.iloc[0]['lyrics'], filters=['punct', 'lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh baby how you doing\\nyou know im gonna cut right to the chase\\nsome women were made but me myself\\ni like to think that i was created for a special purpose\\nyou know whats more special than you you feel me\\nits on baby lets get lost\\nyou dont need to call into work cause youre the boss\\nfor real want you to show me how you feel\\ni consider myself lucky thats a big deal\\nwhy well you got the key to my heart\\nbut you aint gonna need it id rather you open up my body\\nand show me secrets you didnt know was inside\\nno need for me to lie\\nits too big its too wide\\nits too strong it wont fit\\nits too much its too tough\\nhe talk like this cause he can back it up\\nhe got a big ego such a huge ego\\ni love his big ego its too much\\nhe walk like this cause he can back it up\\nusually im humble right now i dont choose\\nyou can leave with me or you could have the blues\\nsome call it arrogant i call it confident\\nyou decide when you find on what im working with\\ndamn i know im killing you with them legs\\nbetter yet them thighs\\nmatter a fact its my smile or maybe my eyes\\nboy you a site to see kind of something like me\\nits too big its too wide\\nits too strong it wont fit\\nits too much its too tough\\ni talk like this cause i can back it up\\ni got a big ego such a huge ego\\nbut he love my big ego its too much\\ni walk like this cause i can back it up\\ni i walk like this cause i can back it up\\ni i talk like this cause i can back it up\\ni i can back it up i can back it up\\ni walk like this cause i can back it up\\nits too big its too wide\\nits too strong it wont fit\\nits too much its too tough\\nhe talk like this cause he can back it up\\nhe got a big ego such a huge ego such a huge ego\\ni love his big ego its too much\\nhe walk like this cause he can back it up\\nego so big you must admit\\ni got every reason to feel like im that bitch\\nego so strong if you aint know\\ni dont need no beat i can sing it with piano'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[0][\"lyrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_s.iloc[0][\"lyrics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export sanitized dataset to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_s.drop(labels=[\"index\",\"song\",\"year\",\"artist\"], axis=1, inplace=True)\n",
    "# df_s[\"genre\"] = df_s[\"genre\"].apply(to_lower)\n",
    "# df_s.to_csv(OUT_DATASET, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the sanitized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(OUT_DATASET)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
